#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YouTube Video/Playlist Transkript Olu≈üturucu - √áoklu Motor Destekli
Whisper, Vosk, Google Speech API Desteƒüi ile
GPU Destekli, Konu≈ümacƒ± Ayrƒ±mƒ± ve ZIP ƒ∞ndirme √ñzellikli
"""

import os
import re
import time
import glob
import torch
import base64
import subprocess
from pathlib import Path
from datetime import timedelta
import gc
import json
import zipfile
import shutil
import warnings
import sys
from typing import List, Dict, Optional, Tuple, Union
import tkinter as tk
from tkinter import filedialog
import webbrowser
import threading
import queue

# Docker ortamƒ± kontrol√º
IS_DOCKER = os.environ.get('CONTAINER_ENV') == 'docker'

if IS_DOCKER:
    # GUI fonksiyonlarƒ±nƒ± devre dƒ±≈üƒ± bƒ±rak
    import sys
    sys.modules['tkinter'] = None

warnings.filterwarnings("ignore")

# Global deƒüi≈üken - t√ºm transkript dosyalarƒ±nƒ± takip etmek i√ßin
all_transcript_files = []

# Konu≈ümacƒ± ayrƒ±mƒ± i√ßin pipeline
diarization_pipeline = None

# Desteklenen dosya formatlarƒ±
VIDEO_FORMATS = ['.mp4', '.avi', '.mov', '.mkv', '.webm', '.flv', '.wmv', '.m4v']
AUDIO_FORMATS = ['.mp3', '.wav', '.ogg', '.m4a', '.flac', '.aac', '.wma']

# Renk kodlarƒ±
class Colors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKCYAN = '\033[96m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'


def install_requirements():
    """Gerekli paketleri y√ºkler"""
    print(f"{Colors.OKBLUE}Gerekli paketler kontrol ediliyor...{Colors.ENDC}")
    
    requirements = {
        'torch': 'torch>=2.0.0',
        'torchaudio': 'torchaudio>=2.0.0',
        'whisper': 'openai-whisper',
        'yt_dlp': 'yt-dlp',
        'vosk': 'vosk',
        'SpeechRecognition': 'SpeechRecognition',
        'pydub': 'pydub',
        'pyannote.audio': 'pyannote.audio',
        'google-cloud-speech': 'google-cloud-speech',
        'numpy': 'numpy<2.0.0',  # Uyumluluk i√ßin
        'scipy': 'scipy',
        'matplotlib': 'matplotlib',
    }
    
    for module_name, pip_name in requirements.items():
        try:
            if module_name == 'whisper':
                import whisper
            elif module_name == 'yt_dlp':
                import yt_dlp
            elif module_name == 'SpeechRecognition':
                import speech_recognition
            elif module_name == 'google-cloud-speech':
                from google.cloud import speech
            else:
                __import__(module_name)
            print(f"{Colors.OKGREEN}‚úÖ {module_name} bulundu{Colors.ENDC}")
        except ImportError:
            print(f"{Colors.WARNING}üì¶ {module_name} y√ºkleniyor...{Colors.ENDC}")
            try:
                subprocess.check_call([sys.executable, "-m", "pip", "install", pip_name])
                print(f"{Colors.OKGREEN}‚úÖ {module_name} y√ºklendi{Colors.ENDC}")
            except:
                print(f"{Colors.FAIL}‚ùå {module_name} y√ºklenemedi. Manuel olarak y√ºkleyin: pip install {pip_name}{Colors.ENDC}")


# Program ba≈üƒ±nda gereksinimleri kontrol et
try:
    install_requirements()
except Exception as e:
    print(f"{Colors.FAIL}Paket y√ºkleme hatasƒ±: {e}{Colors.ENDC}")

# ≈ûimdi import'larƒ± yap
try:
    import whisper
except:
    whisper = None

try:
    import vosk
except:
    vosk = None

try:
    import speech_recognition as sr
except:
    sr = None

try:
    from google.cloud import speech
except:
    speech = None

try:
    from pydub import AudioSegment
    from pydub.silence import split_on_silence
except:
    AudioSegment = None


# Transkript motorlarƒ±
class TranscriptEngine:
    WHISPER = "whisper"
    VOSK = "vosk"
    GOOGLE = "google"
    
    @staticmethod
    def get_available_engines():
        """Kullanƒ±labilir motorlarƒ± d√∂nd√ºr√ºr"""
        engines = []
        if whisper is not None:
            engines.append(TranscriptEngine.WHISPER)
        if vosk is not None:
            engines.append(TranscriptEngine.VOSK)
        if sr is not None:
            engines.append(TranscriptEngine.GOOGLE)
        return engines


# Vosk modelleri - G√ºncel linkler ve alternatifler
VOSK_MODELS = {
    'tr': [
        'https://alphacephei.com/vosk/models/vosk-model-small-tr-0.3.zip',  # K√º√ß√ºk model
        'https://alphacephei.com/vosk/models/vosk-model-tr-0.3.zip',  # B√ºy√ºk model
    ],
    'en': [
        'https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip',  # K√º√ß√ºk
        'https://alphacephei.com/vosk/models/vosk-model-en-us-0.22.zip',  # B√ºy√ºk
    ],
    'de': ['https://alphacephei.com/vosk/models/vosk-model-de-0.21.zip'],
    'fr': ['https://alphacephei.com/vosk/models/vosk-model-fr-0.22.zip'],
    'es': ['https://alphacephei.com/vosk/models/vosk-model-es-0.42.zip'],
    'it': ['https://alphacephei.com/vosk/models/vosk-model-it-0.22.zip'],
    'ru': ['https://alphacephei.com/vosk/models/vosk-model-ru-0.42.zip'],
    'ar': ['https://alphacephei.com/vosk/models/vosk-model-ar-mgb2-0.4.zip'],
    'zh': ['https://alphacephei.com/vosk/models/vosk-model-cn-0.22.zip'],
    'ja': ['https://alphacephei.com/vosk/models/vosk-model-ja-0.22.zip'],
}


def clear_screen():
    """Ekranƒ± temizler"""
    os.system('cls' if os.name == 'nt' else 'clear')


def print_header():
    """Program ba≈ülƒ±ƒüƒ±nƒ± yazdƒ±rƒ±r"""
    clear_screen()
    print(f"{Colors.HEADER}{'='*80}{Colors.ENDC}")
    print(f"{Colors.BOLD}{Colors.OKCYAN}YouTube Video/Playlist Transkript Olu≈üturucu - √áoklu Motor{Colors.ENDC}")
    print(f"{Colors.OKGREEN}Whisper ‚Ä¢ Vosk ‚Ä¢ Google Speech ‚Ä¢ GPU Destekli ‚Ä¢ Konu≈ümacƒ± Ayrƒ±mƒ±{Colors.ENDC}")
    print(f"{Colors.HEADER}{'='*80}{Colors.ENDC}\n")


def get_user_choice(prompt: str, options: List[str], allow_custom: bool = False) -> str:
    """Kullanƒ±cƒ±dan se√ßim alƒ±r"""
    print(f"\n{Colors.BOLD}{prompt}{Colors.ENDC}")
    for i, option in enumerate(options, 1):
        print(f"{Colors.OKBLUE}{i}.{Colors.ENDC} {option}")
    
    if allow_custom:
        print(f"{Colors.OKBLUE}{len(options)+1}.{Colors.ENDC} √ñzel deƒüer gir")
    
    while True:
        try:
            choice = input(f"\n{Colors.WARNING}Se√ßiminiz: {Colors.ENDC}")
            choice_int = int(choice)
            
            if 1 <= choice_int <= len(options):
                return options[choice_int - 1]
            elif allow_custom and choice_int == len(options) + 1:
                return input(f"{Colors.WARNING}√ñzel deƒüer: {Colors.ENDC}")
            else:
                print(f"{Colors.FAIL}Ge√ßersiz se√ßim! L√ºtfen tekrar deneyin.{Colors.ENDC}")
        except ValueError:
            print(f"{Colors.FAIL}L√ºtfen bir sayƒ± girin!{Colors.ENDC}")


def get_yes_no(prompt: str) -> bool:
    """Evet/Hayƒ±r sorusu sorar"""
    while True:
        response = input(f"\n{Colors.WARNING}{prompt} (E/H): {Colors.ENDC}").strip().upper()
        if response in ['E', 'EVET', 'Y', 'YES']:
            return True
        elif response in ['H', 'HAYIR', 'N', 'NO']:
            return False
        else:
            print(f"{Colors.FAIL}L√ºtfen E veya H girin!{Colors.ENDC}")


def download_vosk_model(language: str) -> Optional[str]:
    """Vosk modelini indirir ve yolunu d√∂nd√ºr√ºr"""
    if language not in VOSK_MODELS:
        print(f"{Colors.FAIL}Vosk i√ßin {language} dili desteklenmiyor!{Colors.ENDC}")
        return None
    
    model_urls = VOSK_MODELS[language] if isinstance(VOSK_MODELS[language], list) else [VOSK_MODELS[language]]
    
    for model_url in model_urls:
        model_name = os.path.basename(model_url).replace('.zip', '')
        model_path = os.path.join(os.path.expanduser('~'), '.vosk', model_name)
        
        if os.path.exists(model_path):
            print(f"{Colors.OKGREEN}Vosk modeli mevcut: {model_path}{Colors.ENDC}")
            return model_path
        
        print(f"{Colors.OKBLUE}Vosk modeli indiriliyor: {model_name}...{Colors.ENDC}")
        
        try:
            import urllib.request
            import zipfile
            
            os.makedirs(os.path.dirname(model_path), exist_ok=True)
            
            # Model indir
            zip_path = model_path + '.zip'
            print(f"ƒ∞ndirme URL: {model_url}")
            
            # ƒ∞ndirme i≈ülemi i√ßin timeout ekle
            urllib.request.urlretrieve(model_url, zip_path)
            
            # ZIP'i a√ß
            print(f"ZIP dosyasƒ± a√ßƒ±lƒ±yor...")
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(os.path.dirname(model_path))
            
            # ZIP'i sil
            os.remove(zip_path)
            
            print(f"{Colors.OKGREEN}Vosk modeli indirildi: {model_path}{Colors.ENDC}")
            return model_path
            
        except urllib.error.HTTPError as e:
            print(f"{Colors.WARNING}Model indirilemedi ({e}), bir sonraki deneniyor...{Colors.ENDC}")
            continue
        except Exception as e:
            print(f"{Colors.WARNING}Vosk modeli indirme hatasƒ±: {e}{Colors.ENDC}")
            continue
    
    # T√ºm modeller ba≈üarƒ±sƒ±z oldu
    print(f"{Colors.FAIL}Vosk modeli indirilemedi: {language}{Colors.ENDC}")
    
    # Alternatif √ß√∂z√ºm √∂ner
    print(f"\n{Colors.WARNING}Alternatif √á√∂z√ºmler:{Colors.ENDC}")
    print(f"1. Manuel indirme: {model_urls[0]}")
    print(f"2. ƒ∞ndirdiƒüiniz ZIP'i ≈üuraya √ßƒ±karƒ±n: ~/.vosk/")
    print(f"3. Whisper veya Google Speech API kullanƒ±n")
    
    return None


def transcribe_with_whisper(audio_path: str, language: str = "tr", 
                           model_size: str = "medium", high_quality: bool = True,
                           timestamp_output: bool = True) -> Dict:
    """Whisper ile transkript olu≈üturur"""
    if whisper is None:
        raise Exception("Whisper y√ºkl√º deƒüil!")
    
    print(f"{Colors.OKBLUE}üéôÔ∏è Whisper ile transkript olu≈üturuluyor...{Colors.ENDC}")
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = whisper.load_model(model_size, device=device)
    
    options = {
        "language": language,
        "task": "transcribe",
        "verbose": False,
    }
    
    if high_quality:
        options.update({
            "beam_size": 8,
            "best_of": 8,
            "temperature": [0.0, 0.2, 0.4, 0.6],
            "compression_ratio_threshold": 2.0,
            "condition_on_previous_text": True,
            "fp16": torch.cuda.is_available()
        })
    
    result = model.transcribe(audio_path, **options)
    
    segments = []
    if timestamp_output and "segments" in result:
        for segment in result["segments"]:
            segments.append({
                "start": segment["start"],
                "end": segment["end"],
                "text": segment["text"]
            })
    
    return {
        "text": result["text"],
        "segments": segments,
        "engine": "whisper"
    }


def transcribe_with_vosk(audio_path: str, language: str = "tr") -> Dict:
    """Vosk ile transkript olu≈üturur"""
    if vosk is None:
        raise Exception("Vosk y√ºkl√º deƒüil!")
    
    print(f"{Colors.OKBLUE}üéôÔ∏è Vosk ile transkript olu≈üturuluyor...{Colors.ENDC}")
    
    # Model indir
    model_path = download_vosk_model(language)
    if not model_path:
        raise Exception(f"Vosk modeli indirilemedi: {language}")
    
    # WAV'a d√∂n√º≈üt√ºr (Vosk WAV istiyor)
    wav_path = audio_path.replace(os.path.splitext(audio_path)[1], '_vosk.wav')
    cmd = [
        'ffmpeg', '-i', audio_path,
        '-ar', '16000', '-ac', '1', '-f', 'wav',
        '-y', wav_path
    ]
    subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    
    # Model y√ºkle
    model = vosk.Model(model_path)
    rec = vosk.KaldiRecognizer(model, 16000)
    rec.SetWords(True)
    
    # Ses dosyasƒ±nƒ± oku
    import wave
    wf = wave.open(wav_path, 'rb')
    
    results = []
    full_text = []
    
    while True:
        data = wf.readframes(4000)
        if len(data) == 0:
            break
        if rec.AcceptWaveform(data):
            result = json.loads(rec.Result())
            if 'result' in result:
                results.extend(result['result'])
                full_text.append(result.get('text', ''))
    
    final_result = json.loads(rec.FinalResult())
    if 'result' in final_result:
        results.extend(final_result['result'])
        full_text.append(final_result.get('text', ''))
    
    wf.close()
    
    # Ge√ßici WAV dosyasƒ±nƒ± sil
    if os.path.exists(wav_path):
        os.remove(wav_path)
    
    # Segmentleri olu≈ütur
    segments = []
    for word_info in results:
        if 'start' in word_info and 'end' in word_info:
            segments.append({
                "start": word_info['start'],
                "end": word_info['end'],
                "text": word_info['word']
            })
    
    return {
        "text": ' '.join(full_text),
        "segments": segments,
        "engine": "vosk"
    }


def transcribe_with_google(audio_path: str, language: str = "tr") -> Dict:
    """Google Speech API ile transkript olu≈üturur"""
    if sr is None:
        raise Exception("SpeechRecognition y√ºkl√º deƒüil!")
    
    print(f"{Colors.OKBLUE}üéôÔ∏è Google Speech API ile transkript olu≈üturuluyor...{Colors.ENDC}")
    
    recognizer = sr.Recognizer()
    
    # Ses dosyasƒ±nƒ± par√ßalara b√∂l (Google API'nin limiti var)
    if AudioSegment:
        audio = AudioSegment.from_file(audio_path)
        
        # Mono ve 16kHz'e d√∂n√º≈üt√ºr
        audio = audio.set_channels(1).set_frame_rate(16000)
        
        # 1 dakikalƒ±k par√ßalara b√∂l
        chunk_length_ms = 60000  # 1 dakika
        chunks = [audio[i:i+chunk_length_ms] for i in range(0, len(audio), chunk_length_ms)]
    else:
        # Pydub yoksa tek par√ßa olarak i≈üle
        chunks = [None]
    
    full_text = []
    segments = []
    current_time = 0
    
    for i, chunk in enumerate(chunks):
        try:
            if AudioSegment and chunk:
                # Ge√ßici dosya olu≈ütur
                temp_path = f"temp_chunk_{i}.wav"
                chunk.export(temp_path, format="wav")
                audio_file = sr.AudioFile(temp_path)
            else:
                audio_file = sr.AudioFile(audio_path)
            
            with audio_file as source:
                audio_data = recognizer.record(source)
            
            # Google Speech API ile tanƒ±
            text = recognizer.recognize_google(audio_data, language=f"{language}-{language.upper()}")
            full_text.append(text)
            
            # Basit segment olu≈ütur
            if text:
                segment_duration = len(chunk) / 1000.0 if chunk else 60.0
                segments.append({
                    "start": current_time,
                    "end": current_time + segment_duration,
                    "text": text
                })
                current_time += segment_duration
            
            # Ge√ßici dosyayƒ± sil
            if AudioSegment and chunk and os.path.exists(temp_path):
                os.remove(temp_path)
                
        except sr.UnknownValueError:
            print(f"{Colors.WARNING}B√∂l√ºm {i+1} anla≈üƒ±lamadƒ±{Colors.ENDC}")
        except sr.RequestError as e:
            print(f"{Colors.WARNING}Google API hatasƒ±: {e}{Colors.ENDC}")
        except Exception as e:
            print(f"{Colors.WARNING}B√∂l√ºm {i+1} hatasƒ±: {e}{Colors.ENDC}")
    
    return {
        "text": ' '.join(full_text),
        "segments": segments,
        "engine": "google"
    }


def transcribe_with_fallback(audio_path: str, language: str = "tr", 
                           preferred_engine: str = None,
                           engine_order: List[str] = None,
                           **kwargs) -> Dict:
    """Birden fazla motoru deneyerek transkript olu≈üturur"""
    
    available_engines = TranscriptEngine.get_available_engines()
    
    if not available_engines:
        raise Exception("Hi√ßbir transkript motoru bulunamadƒ±!")
    
    # Motor sƒ±rasƒ±nƒ± belirle
    if engine_order is None:
        engine_order = []
        
        # Tercih edilen motoru ba≈üa al
        if preferred_engine and preferred_engine in available_engines:
            engine_order.append(preferred_engine)
        
        # Diƒüer motorlarƒ± ekle
        default_order = [TranscriptEngine.WHISPER, TranscriptEngine.VOSK, TranscriptEngine.GOOGLE]
        for engine in default_order:
            if engine in available_engines and engine not in engine_order:
                engine_order.append(engine)
    
    print(f"{Colors.OKBLUE}Kullanƒ±lacak motor sƒ±rasƒ±: {' ‚Üí '.join(engine_order)}{Colors.ENDC}")
    
    # Her motoru dene
    for i, engine in enumerate(engine_order):
        try:
            print(f"\n{Colors.OKCYAN}Motor deneniyor ({i+1}/{len(engine_order)}): {engine}{Colors.ENDC}")
            
            if engine == TranscriptEngine.WHISPER:
                result = transcribe_with_whisper(
                    audio_path, 
                    language=language,
                    model_size=kwargs.get('model_size', 'medium'),
                    high_quality=kwargs.get('high_quality', True),
                    timestamp_output=kwargs.get('timestamp_output', True)
                )
            elif engine == TranscriptEngine.VOSK:
                result = transcribe_with_vosk(audio_path, language=language)
            elif engine == TranscriptEngine.GOOGLE:
                result = transcribe_with_google(audio_path, language=language)
            else:
                continue
            
            print(f"{Colors.OKGREEN}‚úÖ {engine} ba≈üarƒ±lƒ±!{Colors.ENDC}")
            return result
            
        except Exception as e:
            print(f"{Colors.FAIL}‚ùå {engine} ba≈üarƒ±sƒ±z: {str(e)}{Colors.ENDC}")
            if i < len(engine_order) - 1:
                print(f"{Colors.WARNING}Bir sonraki motor deneniyor...{Colors.ENDC}")
            continue
    
    raise Exception("T√ºm transkript motorlarƒ± ba≈üarƒ±sƒ±z oldu!")


def select_files_or_folder_gui() -> Tuple[List[str], str]:
    """Dosya veya klas√∂r se√ßmek i√ßin GUI penceresi a√ßar"""
    root = tk.Tk()
    root.withdraw()
    
    # √ñnce se√ßim tipini sor
    print(f"\n{Colors.BOLD}Ne se√ßmek istersiniz?{Colors.ENDC}")
    print(f"{Colors.OKBLUE}1.{Colors.ENDC} Tek dosya")
    print(f"{Colors.OKBLUE}2.{Colors.ENDC} Birden fazla dosya")
    print(f"{Colors.OKBLUE}3.{Colors.ENDC} Klas√∂r (i√ßindeki t√ºm video/ses dosyalarƒ±)")
    
    choice = input(f"\n{Colors.WARNING}Se√ßiminiz: {Colors.ENDC}")
    
    output_dir = None
    
    if choice == "1":
        # Tek dosya se√ß
        file_path = filedialog.askopenfilename(
            title="Video veya Ses Dosyasƒ± Se√ßin",
            filetypes=[
                ("Video/Ses Dosyalarƒ±", " ".join(f"*{ext}" for ext in VIDEO_FORMATS + AUDIO_FORMATS)),
                ("Video Dosyalarƒ±", " ".join(f"*{ext}" for ext in VIDEO_FORMATS)),
                ("Ses Dosyalarƒ±", " ".join(f"*{ext}" for ext in AUDIO_FORMATS)),
                ("T√ºm Dosyalar", "*.*")
            ]
        )
        root.destroy()
        
        if file_path:
            output_dir = os.path.dirname(file_path)
            return [file_path], output_dir
        else:
            return [], None
    
    elif choice == "2":
        # Birden fazla dosya se√ß
        file_paths = filedialog.askopenfilenames(
            title="Video veya Ses Dosyalarƒ±nƒ± Se√ßin (Ctrl ile √ßoklu se√ßim)",
            filetypes=[
                ("Video/Ses Dosyalarƒ±", " ".join(f"*{ext}" for ext in VIDEO_FORMATS + AUDIO_FORMATS)),
                ("Video Dosyalarƒ±", " ".join(f"*{ext}" for ext in VIDEO_FORMATS)),
                ("Ses Dosyalarƒ±", " ".join(f"*{ext}" for ext in AUDIO_FORMATS)),
                ("T√ºm Dosyalar", "*.*")
            ]
        )
        root.destroy()
        
        if file_paths:
            output_dir = os.path.dirname(file_paths[0])
            return list(file_paths), output_dir
        else:
            return [], None
    
    elif choice == "3":
        # Klas√∂r se√ß
        folder_path = filedialog.askdirectory(
            title="Video/Ses Dosyalarƒ±nƒ± ƒ∞√ßeren Klas√∂r√º Se√ßin"
        )
        root.destroy()
        
        if folder_path:
            # Klas√∂rdeki t√ºm video/ses dosyalarƒ±nƒ± bul
            files = []
            for ext in VIDEO_FORMATS + AUDIO_FORMATS:
                files.extend(glob.glob(os.path.join(folder_path, f"*{ext}")))
                files.extend(glob.glob(os.path.join(folder_path, f"*{ext.upper()}")))
            
            if files:
                return files, folder_path
            else:
                print(f"{Colors.FAIL}Se√ßilen klas√∂rde video/ses dosyasƒ± bulunamadƒ±!{Colors.ENDC}")
                return [], None
        else:
            return [], None
    
    else:
        root.destroy()
        print(f"{Colors.FAIL}Ge√ßersiz se√ßim!{Colors.ENDC}")
        return [], None


def check_dependencies():
    """Gerekli baƒüƒ±mlƒ±lƒ±klarƒ± kontrol eder"""
    # FFmpeg kontrol√º
    try:
        subprocess.run(['ffmpeg', '-version'], capture_output=True, check=True)
    except (subprocess.CalledProcessError, FileNotFoundError):
        print(f"{Colors.FAIL}‚ùå FFmpeg bulunamadƒ±. L√ºtfen https://ffmpeg.org adresinden indirip PATH'e ekleyin.{Colors.ENDC}")
        return False
    
    # yt-dlp'yi Python mod√ºl√º olarak kontrol et
    try:
        import yt_dlp
        print(f"{Colors.OKGREEN}‚úÖ yt-dlp mod√ºl√º bulundu{Colors.ENDC}")
    except ImportError:
        print(f"{Colors.FAIL}‚ùå yt-dlp mod√ºl√º bulunamadƒ±. pip install yt-dlp komutu ile y√ºkleyin.{Colors.ENDC}")
        return False
    
    # Transkript motorlarƒ±nƒ± kontrol et
    available_engines = TranscriptEngine.get_available_engines()
    if not available_engines:
        print(f"{Colors.FAIL}‚ùå Hi√ßbir transkript motoru bulunamadƒ±!{Colors.ENDC}")
        return False
    else:
        print(f"{Colors.OKGREEN}‚úÖ Kullanƒ±labilir motorlar: {', '.join(available_engines)}{Colors.ENDC}")
    
    return True


def gpu_baglanti_kontrol():
    """GPU baƒülantƒ±sƒ±nƒ± kontrol et"""
    if torch.cuda.is_available():
        gpu_tipi = torch.cuda.get_device_name(0)
        print(f"{Colors.OKGREEN}‚úÖ GPU bulundu: {gpu_tipi}{Colors.ENDC}")
        return True
    else:
        print(f"{Colors.WARNING}‚ö†Ô∏è GPU bulunamadƒ±. CPU kullanƒ±lacak (daha yava≈ü olabilir){Colors.ENDC}")
        return False


def clean_filename(filename):
    """Dosya adƒ±nƒ± Windows ve Linux i√ßin g√ºvenli hale getirir"""
    forbidden_chars = ['<', '>', ':', '"', '/', '\\', '|', '?', '*']
    for char in forbidden_chars:
        filename = filename.replace(char, '')

    if len(filename) > 100:
        filename = filename[:100] + "..."

    filename = filename.replace(' ', '_')
    filename = re.sub(r'_+', '_', filename)
    filename = filename.strip('_')

    return filename


def initialize_diarization_pipeline(huggingface_token: str, min_speakers: int = 2, max_speakers: int = 10):
    """Konu≈ümacƒ± ayrƒ±mƒ± pipeline'ƒ±nƒ± ba≈ülat"""
    global diarization_pipeline
    
    if not huggingface_token:
        print(f"{Colors.WARNING}‚ö†Ô∏è Konu≈ümacƒ± ayrƒ±mƒ± i√ßin HuggingFace token gerekli!")
        print(f"üìå Token almak i√ßin: https://huggingface.co/settings/tokens")
        print(f"üìå pyannote/speaker-diarization-3.1 modelini kabul etmeyi unutmayƒ±n!{Colors.ENDC}")
        return False
    
    try:
        from pyannote.audio import Pipeline
        print(f"{Colors.OKBLUE}üé§ Konu≈ümacƒ± ayrƒ±mƒ± modeli y√ºkleniyor...{Colors.ENDC}")
        
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        diarization_pipeline = Pipeline.from_pretrained(
            "pyannote/speaker-diarization-3.1",
            use_auth_token=huggingface_token
        )
        
        diarization_pipeline.to(device)
        
        print(f"{Colors.OKGREEN}‚úÖ Konu≈ümacƒ± ayrƒ±mƒ± modeli y√ºklendi ({device}){Colors.ENDC}")
        return True
        
    except Exception as e:
        print(f"{Colors.FAIL}‚ùå Konu≈ümacƒ± ayrƒ±mƒ± modeli y√ºklenemedi: {str(e)}{Colors.ENDC}")
        diarization_pipeline = None
        return False


def perform_speaker_diarization(audio_path: str, min_speakers: int = 2, max_speakers: int = 10):
    """Ses dosyasƒ± i√ßin konu≈ümacƒ± ayrƒ±mƒ± yap"""
    global diarization_pipeline
    
    if not diarization_pipeline:
        return None
    
    try:
        print(f"{Colors.OKBLUE}üé§ Konu≈ümacƒ±lar tespit ediliyor...{Colors.ENDC}")
        
        diarization = diarization_pipeline(
            audio_path,
            min_speakers=min_speakers,
            max_speakers=max_speakers
        )
        
        speaker_segments = []
        speakers_found = set()
        
        for turn, _, speaker in diarization.itertracks(yield_label=True):
            speakers_found.add(speaker)
            speaker_segments.append({
                'start': turn.start,
                'end': turn.end,
                'speaker': speaker
            })
        
        print(f"{Colors.OKGREEN}‚úÖ {len(speakers_found)} konu≈ümacƒ± tespit edildi{Colors.ENDC}")
        return speaker_segments
        
    except Exception as e:
        print(f"{Colors.WARNING}‚ö†Ô∏è Konu≈ümacƒ± ayrƒ±mƒ± hatasƒ±: {str(e)}{Colors.ENDC}")
        return None


def assign_speakers_to_transcript(transcript_segments, speaker_segments):
    """Transkript segmentlerine konu≈ümacƒ± bilgisi ekle"""
    if not speaker_segments:
        return transcript_segments
    
    enhanced_segments = []
    
    for segment in transcript_segments:
        seg_start = segment['start']
        seg_end = segment['end']
        seg_mid = (seg_start + seg_end) / 2
        
        best_speaker = "Bilinmeyen"
        best_overlap = 0
        
        for speaker_seg in speaker_segments:
            if speaker_seg['start'] <= seg_mid <= speaker_seg['end']:
                best_speaker = speaker_seg['speaker']
                break
            
            overlap_start = max(seg_start, speaker_seg['start'])
            overlap_end = min(seg_end, speaker_seg['end'])
            overlap = max(0, overlap_end - overlap_start)
            
            if overlap > best_overlap:
                best_overlap = overlap
                best_speaker = speaker_seg['speaker']
        
        segment['speaker'] = best_speaker
        enhanced_segments.append(segment)
    
    return enhanced_segments


def get_video_title_and_id(video_url: str) -> Tuple[str, str]:
    """Video URL'sinden ba≈ülƒ±k ve ID'yi alƒ±r"""
    try:
        import yt_dlp
        
        ydl_opts = {
            'quiet': True,
            'no_warnings': True,
            'skip_download': True
        }
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(video_url, download=False)
            title = info.get('title', 'Video')
            video_id = info.get('id', '')
            
        return clean_filename(title), video_id
        
    except Exception as e:
        print(f"{Colors.WARNING}Video bilgileri alƒ±namadƒ±: {str(e)}{Colors.ENDC}")
        video_id = extract_youtube_id(video_url)
        return f"Video_{video_id}", video_id


def is_playlist_url(url: str) -> bool:
    """URL'nin playlist olup olmadƒ±ƒüƒ±nƒ± kontrol eder"""
    playlist_patterns = [
        r'[?&]list=([^&]+)',
        r'youtube\.com/playlist\?list=([^&]+)',
    ]

    for pattern in playlist_patterns:
        if re.search(pattern, url):
            return True
    return False


def extract_youtube_id(url: str) -> Optional[str]:
    """YouTube URL'sinden video ID'sini √ßƒ±karƒ±r"""
    if '&' in url:
        url = url.split('&')[0]

    patterns = [
        r'(?:https?:\/\/)?(?:www\.)?youtube\.com\/watch\?v=([^\/\?\&]+)',
        r'(?:https?:\/\/)?(?:www\.)?youtube\.com\/embed\/([^\/\?\&]+)',
        r'(?:https?:\/\/)?(?:www\.)?youtube\.com\/v\/([^\/\?\&]+)',
        r'(?:https?:\/\/)?(?:www\.)?youtube\.com\/shorts\/([^\/\?\&]+)',
        r'(?:https?:\/\/)?(?:www\.)?youtu\.be\/([^\/\?\&]+)'
    ]

    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)

    return None


def get_playlist_videos(playlist_url: str, max_videos: int = 50) -> List[Dict]:
    """Playlist'teki videolarƒ± listeler"""
    print(f"{Colors.OKBLUE}Playlist bilgileri alƒ±nƒ±yor...{Colors.ENDC}")

    try:
        import yt_dlp
        
        ydl_opts = {
            'quiet': True,
            'no_warnings': True,
            'extract_flat': True,
            'playlistend': max_videos,
            'ignoreerrors': True
        }
        
        videos = []
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            playlist_info = ydl.extract_info(playlist_url, download=False)
            
            if 'entries' in playlist_info:
                for entry in playlist_info['entries']:
                    if entry is None:
                        continue
                    
                    video_id = entry.get('id', '')
                    title = entry.get('title', 'Video')
                    duration = entry.get('duration', 0)
                    
                    if duration and duration != 0:
                        duration_str = str(timedelta(seconds=duration))
                    else:
                        duration_str = 'Bilinmiyor'
                    
                    videos.append({
                        'id': video_id,
                        'title': title,
                        'clean_title': clean_filename(title),
                        'duration': duration_str,
                        'url': f'https://www.youtube.com/watch?v={video_id}'
                    })

        return videos

    except Exception as e:
        print(f"{Colors.FAIL}Playlist bilgileri alƒ±namadƒ±: {str(e)}{Colors.ENDC}")
        return []


def download_youtube_audio_direct(youtube_url: str, output_path: Optional[str] = None) -> str:
    """YouTube videosunu direkt MP3 olarak indirir"""
    import yt_dlp
    
    video_id = extract_youtube_id(youtube_url)
    if not video_id:
        raise ValueError(f"Ge√ßerli bir YouTube URL'si deƒüil: {youtube_url}")

    print(f"{Colors.OKBLUE}YouTube video ID: {video_id}")
    print(f"Ses dosyasƒ± indiriliyor (direkt MP3)...{Colors.ENDC}")

    if output_path is None:
        timestamp = int(time.time())
        output_path = f"youtube_audio_{video_id}_{timestamp}.mp3"

    if not output_path.endswith('.mp3'):
        output_path = output_path.replace(os.path.splitext(output_path)[1], '.mp3')

    old_files = glob.glob(f"youtube_audio_{video_id}_*.mp3")
    for old_file in old_files:
        try:
            os.remove(old_file)
        except:
            pass

    ydl_opts = {
        'format': 'bestaudio[ext=m4a]/bestaudio/best',
        'extractaudio': True,
        'audioformat': 'mp3',
        'audioquality': 0,
        'outtmpl': output_path.replace('.mp3', '.%(ext)s'),
        'postprocessors': [{
            'key': 'FFmpegExtractAudio',
            'preferredcodec': 'mp3',
            'preferredquality': '192',
        }],
        'quiet': True,
        'no_warnings': True,
        'ignoreerrors': True,
        'retries': 5,
        'fragment_retries': 5,
        'socket_timeout': 30
    }

    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(youtube_url, download=True)
            
        expected_file = output_path
        if not os.path.exists(expected_file):
            directory = os.path.dirname(expected_file) if os.path.dirname(expected_file) else '.'
            mp3_files = glob.glob(os.path.join(directory, f"*{video_id}*.mp3"))
            if mp3_files:
                expected_file = max(mp3_files, key=os.path.getctime)
                if expected_file != output_path:
                    os.rename(expected_file, output_path)
                    expected_file = output_path

        if not os.path.exists(expected_file):
            raise Exception("ƒ∞ndirilen ses dosyasƒ± bulunamadƒ±")

        try:
            duration_cmd = [
                'ffprobe',
                '-v', 'error',
                '-show_entries', 'format=duration',
                '-of', 'default=noprint_wrappers=1:nokey=1',
                expected_file
            ]

            duration = float(subprocess.check_output(duration_cmd, timeout=30).decode('utf-8').strip())
            print(f"{Colors.OKGREEN}Ses dosyasƒ± ba≈üarƒ±yla indirildi: {expected_file}")
            print(f"Ses uzunluƒüu: {duration:.1f} saniye ({format_time_duration(duration)})")
            print(f"Dosya boyutu: {os.path.getsize(expected_file) / (1024*1024):.1f} MB{Colors.ENDC}")
        except:
            print(f"{Colors.OKGREEN}Ses dosyasƒ± ba≈üarƒ±yla indirildi: {expected_file}{Colors.ENDC}")

        return expected_file

    except Exception as e:
        raise Exception(f"Ses indirme hatasƒ±: {str(e)}")


def format_time(seconds: float) -> str:
    """Saniye cinsinden zamanƒ± SS:DD:SS formatƒ±na d√∂n√º≈üt√ºr√ºr"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    seconds = int(seconds % 60)
    return f"{hours:02d}:{minutes:02d}:{seconds:02d}"


def format_time_duration(seconds: float) -> str:
    """Saniye cinsinden s√ºreyi okunabilir formata d√∂n√º≈üt√ºr√ºr"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)

    if hours > 0:
        return f"{hours} saat {minutes} dakika {secs} saniye"
    elif minutes > 0:
        return f"{minutes} dakika {secs} saniye"
    else:
        return f"{secs} saniye"


def create_zip_archive(file_paths: List[str], zip_name: str = "transkriptler.zip") -> str:
    """Birden fazla dosyayƒ± ZIP ar≈üivi olarak olu≈üturur"""
    with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for file_path in file_paths:
            if os.path.exists(file_path):
                arcname = os.path.basename(file_path)
                zipf.write(file_path, arcname)
    
    zip_size = os.path.getsize(zip_name) / (1024*1024)
    
    print(f"\n{Colors.OKGREEN}üì¶ ZIP ar≈üivi olu≈üturuldu: {zip_name}")
    print(f"üìÅ Dosya sayƒ±sƒ±: {len(file_paths)}")
    print(f"üíæ ZIP boyutu: {zip_size:.2f} MB{Colors.ENDC}")
    
    return zip_name


def get_video_duration(input_file: str) -> float:
    """Video veya ses dosyasƒ±nƒ±n s√ºresini saniye cinsinden d√∂nd√ºr√ºr"""
    cmd = [
        'ffprobe',
        '-v', 'error',
        '-show_entries', 'format=duration',
        '-of', 'default=noprint_wrappers=1:nokey=1',
        input_file
    ]
    output = subprocess.check_output(cmd).decode('utf-8').strip()
    return float(output)


def is_audio_file(file_path: str) -> bool:
    """Dosyanƒ±n ses dosyasƒ± olup olmadƒ±ƒüƒ±nƒ± kontrol eder"""
    ext = os.path.splitext(file_path)[1].lower()
    return ext in AUDIO_FORMATS


def is_video_file(file_path: str) -> bool:
    """Dosyanƒ±n video dosyasƒ± olup olmadƒ±ƒüƒ±nƒ± kontrol eder"""
    ext = os.path.splitext(file_path)[1].lower()
    return ext in VIDEO_FORMATS


def check_file_type(file_path: str) -> str:
    """Dosya t√ºr√ºn√º kontrol eder ve uygun deƒüeri d√∂nd√ºr√ºr"""
    if is_audio_file(file_path):
        return "audio"
    elif is_video_file(file_path):
        return "video"
    else:
        return "unknown"


def optimize_for_whisper(input_path: str) -> str:
    """Video veya ses dosyasƒ±nƒ± Whisper i√ßin optimize eder"""
    file_type = check_file_type(input_path)
    timestamp = int(time.time())
    audio_path = f"{Path(input_path).stem}_audio_{timestamp}.mp3"

    if file_type == "audio":
        cmd = [
            'ffmpeg',
            '-i', input_path,
            '-c:a', 'mp3',
            '-b:a', '192k',
            '-ar', '16000',
            '-ac', '1',
            '-af', 'highpass=f=200,lowpass=f=3000,volume=2',
            '-y',
            audio_path
        ]
    else:
        cmd = [
            'ffmpeg',
            '-i', input_path,
            '-vn',
            '-c:a', 'mp3',
            '-b:a', '192k',
            '-ar', '16000',
            '-ac', '1',
            '-af', 'highpass=f=200,lowpass=f=3000,volume=2',
            '-y',
            audio_path
        ]

    subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    return audio_path


def split_video_ffmpeg(input_file: str, segment_length: int = 15, output_dir: Optional[str] = None) -> List[str]:
    """Video veya ses dosyasƒ±nƒ± belirtilen dakikalƒ±k segmentlere b√∂ler"""
    if output_dir is None:
        output_dir = os.path.dirname(input_file)
        if output_dir == '':
            output_dir = '.'

    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    print(f"{Colors.OKBLUE}Dosya inceleniyor: {input_file}{Colors.ENDC}")
    total_duration = get_video_duration(input_file)

    segment_length_sec = segment_length * 60
    num_segments = int(total_duration / segment_length_sec) + (1 if total_duration % segment_length_sec > 0 else 0)

    print(f"Toplam s√ºre: {total_duration/60:.1f} dakika ({format_time_duration(total_duration)})")
    print(f"Dosya {num_segments} par√ßaya b√∂l√ºnecek ({segment_length} dakikalƒ±k dilimler)...")

    output_files = []

    file_ext = os.path.splitext(input_file)[1]
    if not file_ext:
        file_ext = ".mp3"

    for i in range(num_segments):
        start_time = i * segment_length_sec
        end_time = min((i + 1) * segment_length_sec, total_duration)

        base_name = os.path.splitext(os.path.basename(input_file))[0]
        output_file = os.path.join(output_dir, f"{base_name}_part{i+1:02d}{file_ext}")

        print(f"B√∂l√ºm {i+1}/{num_segments} kesiliyor ({format_time(start_time)} - {format_time(end_time)})...")

        cmd = [
            'ffmpeg',
            '-i', input_file,
            '-ss', str(start_time),
            '-to', str(end_time),
            '-c', 'copy',
            '-y',
            output_file
        ]

        subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        output_files.append(output_file)

    print(f"{Colors.OKGREEN}B√∂lme i≈ülemi tamamlandƒ±. {len(output_files)} par√ßa olu≈üturuldu.{Colors.ENDC}")
    return output_files


def transcribe_segment(audio_path: str, model, language: str = "tr", 
                      high_quality: bool = True, timestamp_output: bool = True, 
                      speaker_diarization: Optional[List] = None,
                      preferred_engine: str = None,
                      engine_order: List[str] = None,
                      model_size: str = "medium") -> Dict:
    """Tek bir ses segmentinin transkriptini olu≈üturur"""
    segment_start_time = time.time()
    print(f"Segment i≈üleniyor: {os.path.basename(audio_path)}")

    try:
        # Yeni √ßoklu motor sistemini kullan
        result_data = transcribe_with_fallback(
            audio_path,
            language=language,
            preferred_engine=preferred_engine,
            engine_order=engine_order,
            model_size=model_size,
            high_quality=high_quality,
            timestamp_output=timestamp_output
        )
        
        transcript_text = result_data["text"]
        segments = result_data.get("segments", [])
        used_engine = result_data.get("engine", "unknown")
        
        # Konu≈ümacƒ± ayrƒ±mƒ± uygula
        if speaker_diarization and segments:
            segments = assign_speakers_to_transcript(segments, speaker_diarization)

        output_path = f"{Path(audio_path).stem}_transkript.txt"

        with open(output_path, "w", encoding="utf-8") as f:
            f.write(f"## Transkript Motoru: {used_engine.upper()} ##\n\n")
            
            if not speaker_diarization:
                f.write(transcript_text)
            else:
                f.write("## KONU≈ûMACI AYRIMLI TRANSKRƒ∞PT ##\n\n")
                current_speaker = None
                speaker_text = ""
                
                for segment in segments:
                    speaker = segment.get("speaker", "Bilinmeyen")
                    text = segment["text"].strip()
                    
                    if speaker != current_speaker:
                        if current_speaker is not None:
                            f.write(f"[{current_speaker}]: {speaker_text}\n\n")
                        current_speaker = speaker
                        speaker_text = text
                    else:
                        speaker_text += " " + text
                
                if current_speaker is not None:
                    f.write(f"[{current_speaker}]: {speaker_text}\n")

            if timestamp_output and segments:
                f.write("\n\n## ZAMANLI TRANSKRƒ∞PT ##\n\n")
                for segment in segments:
                    segment_start = segment["start"]
                    segment_end = segment["end"]
                    text = segment["text"]
                    timestamp = f"[{format_time(segment_start)} --> {format_time(segment_end)}]"
                    
                    if speaker_diarization and "speaker" in segment:
                        speaker = segment["speaker"]
                        f.write(f"{timestamp} [{speaker}]: {text}\n")
                    else:
                        f.write(f"{timestamp} {text}\n")

        segment_elapsed_time = time.time() - segment_start_time
        print(f"Segment tamamlandƒ±: {os.path.basename(output_path)}")
        print(f"ƒ∞≈ülem s√ºresi: {segment_elapsed_time:.2f} saniye ({format_time_duration(segment_elapsed_time)})")
        print(f"Kullanƒ±lan motor: {used_engine}")

        return {
            "path": output_path,
            "text": transcript_text,
            "segments": segments,
            "engine": used_engine
        }
    except Exception as e:
        print(f"{Colors.FAIL}‚ùå Segment i≈üleme hatasƒ±: {str(e)}{Colors.ENDC}")
        import traceback
        traceback.print_exc()
        return {
            "path": f"{Path(audio_path).stem}_hata.txt",
            "text": f"Transkript olu≈üturulamadƒ±: {str(e)}",
            "segments": None,
            "engine": "error"
        }


def merge_transcripts(transcript_results: List[Dict], input_file: str, 
                     timestamp_output: bool = True, custom_filename: Optional[str] = None, 
                     has_speaker_diarization: bool = False, output_dir: Optional[str] = None) -> str:
    """T√ºm transkript sonu√ßlarƒ±nƒ± birle≈ütirir ve bir dosyaya kaydeder"""
    global all_transcript_files

    if custom_filename:
        full_transcript_path = custom_filename
    else:
        base_name = os.path.splitext(os.path.basename(input_file))[0]
        full_transcript_path = f"{base_name}_tam_transkript.txt"
    
    # √áƒ±ktƒ± dizini belirtilmi≈üse kullan
    if output_dir:
        full_transcript_path = os.path.join(output_dir, os.path.basename(full_transcript_path))

    full_text = ""
    all_segments = []
    segment_time_offset = 0
    used_engines = set()

    # Kullanƒ±lan motorlarƒ± topla
    for result in transcript_results:
        if result.get("engine"):
            used_engines.add(result["engine"])

    full_text = f"## Kullanƒ±lan Motorlar: {', '.join(used_engines)} ##\n\n"

    if has_speaker_diarization:
        full_text += "## KONU≈ûMACI AYRIMLI TAM TRANSKRƒ∞PT ##\n\n"
        speaker_texts = {}
        
        for i, result in enumerate(transcript_results):
            if result.get("segments"):
                for segment in result["segments"]:
                    speaker = segment.get("speaker", "Bilinmeyen")
                    if speaker not in speaker_texts:
                        speaker_texts[speaker] = []
                    speaker_texts[speaker].append(segment["text"].strip())
        
        for speaker, texts in sorted(speaker_texts.items()):
            full_text += f"\n[{speaker}]:\n"
            full_text += " ".join(texts) + "\n"
    else:
        for i, result in enumerate(transcript_results):
            full_text += f"\n\n--- B√ñL√úM {i+1} ---\n\n"
            full_text += result["text"]

    if timestamp_output:
        for i, result in enumerate(transcript_results):
            if result.get("segments"):
                for segment in result["segments"]:
                    adjusted_segment = segment.copy()
                    adjusted_segment["start"] += segment_time_offset
                    adjusted_segment["end"] += segment_time_offset
                    all_segments.append(adjusted_segment)

                if result["segments"]:
                    last_segment = result["segments"][-1]
                    segment_time_offset += last_segment["end"]

    with open(full_transcript_path, "w", encoding="utf-8") as f:
        f.write(full_text)

        if timestamp_output and all_segments:
            f.write("\n\n## TAM ZAMANLI TRANSKRƒ∞PT ##\n\n")
            for segment in all_segments:
                start_time = segment["start"]
                end_time = segment["end"]
                text = segment["text"]
                timestamp = f"[{format_time(start_time)} --> {format_time(end_time)}]"
                
                if has_speaker_diarization and "speaker" in segment:
                    speaker = segment["speaker"]
                    f.write(f"{timestamp} [{speaker}]: {text}\n")
                else:
                    f.write(f"{timestamp} {text}\n")

    print(f"{Colors.OKGREEN}Tam transkript olu≈üturuldu: {full_transcript_path}{Colors.ENDC}")
    all_transcript_files.append(full_transcript_path)
    
    return full_transcript_path


def process_file(file_path: str, language: str = "tr", model_size: str = "large", 
                high_quality: bool = True, timestamp_output: bool = True, 
                segment_length_minutes: int = 15, delete_segments_after: bool = True, 
                custom_filename: Optional[str] = None, 
                enable_speaker_diarization: bool = False,
                min_speakers: int = 2, max_speakers: int = 10,
                output_dir: Optional[str] = None,
                preferred_engine: str = None,
                engine_order: List[str] = None) -> Optional[str]:
    """Yerel veya indirilen dosyayƒ± i≈üleyip transkript olu≈üturur"""
    try:
        total_start_time = time.time()

        file_type = check_file_type(file_path)
        file_type_str = "Ses" if file_type == "audio" else "Video"

        print(f"\n{Colors.HEADER}--- 1. {file_type_str.upper()} OPTƒ∞Mƒ∞ZASYONU ---{Colors.ENDC}")
        audio_path = optimize_for_whisper(file_path)
        print(f"{file_type_str} dosyasƒ± optimize edildi: {audio_path}")

        speaker_diarization = None
        if enable_speaker_diarization and diarization_pipeline:
            print(f"\n{Colors.HEADER}--- KONU≈ûMACI AYRIMI ---{Colors.ENDC}")
            speaker_diarization = perform_speaker_diarization(audio_path, min_speakers, max_speakers)

        print(f"\n{Colors.HEADER}--- 2. SES B√ñLME (FFmpeg ile Hƒ±zlƒ± Kesim) ---{Colors.ENDC}")
        audio_segments = split_video_ffmpeg(audio_path, segment_length=segment_length_minutes)

        device = "cuda" if torch.cuda.is_available() else "cpu"
        if device == "cuda":
            print(f"\n{Colors.OKGREEN}GPU kullanƒ±lƒ±yor: {torch.cuda.get_device_name(0)}{Colors.ENDC}")
        else:
            print(f"\n{Colors.WARNING}UYARI: GPU bulunamadƒ±! CPU kullanƒ±lacak{Colors.ENDC}")

        print(f"\n{Colors.HEADER}--- 3. TRANSKRƒ∞PT OLU≈ûTURMA ---{Colors.ENDC}")
        transcript_results = []

        # Whisper modeli artƒ±k her segment i√ßin ayrƒ± y√ºklenecek
        model = None

        for i, segment_path in enumerate(audio_segments):
            print(f"\n{Colors.OKCYAN}Ses par√ßasƒ± {i+1}/{len(audio_segments)} i≈üleniyor...{Colors.ENDC}")

            segment_speaker_diarization = None
            if speaker_diarization:
                segment_duration = get_video_duration(segment_path)
                segment_start_offset = i * segment_length_minutes * 60
                
                segment_speaker_diarization = []
                for speaker_seg in speaker_diarization:
                    adjusted_start = max(0, speaker_seg['start'] - segment_start_offset)
                    adjusted_end = min(segment_duration, speaker_seg['end'] - segment_start_offset)
                    
                    if adjusted_start < segment_duration and adjusted_end > 0:
                        segment_speaker_diarization.append({
                            'start': adjusted_start,
                            'end': adjusted_end,
                            'speaker': speaker_seg['speaker']
                        })

            result = transcribe_segment(
                segment_path,
                model,
                language=language,
                high_quality=high_quality,
                timestamp_output=timestamp_output,
                speaker_diarization=segment_speaker_diarization,
                preferred_engine=preferred_engine,
                engine_order=engine_order,
                model_size=model_size
            )

            transcript_results.append(result)

            print("Bellek temizleniyor...")
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            print("Bellek temizlendi.")

        print(f"\n{Colors.HEADER}--- 4. TRANSKRƒ∞PTLERƒ∞ Bƒ∞RLE≈ûTƒ∞RME ---{Colors.ENDC}")
        full_transcript_path = merge_transcripts(
            transcript_results,
            file_path,
            timestamp_output=timestamp_output,
            custom_filename=custom_filename,
            has_speaker_diarization=(speaker_diarization is not None),
            output_dir=output_dir
        )

        print(f"\n{Colors.OKGREEN}--- ƒ∞≈ûLEM TAMAMLANDI ---{Colors.ENDC}")

        if delete_segments_after:
            print(f"\n{Colors.OKBLUE}Ge√ßici dosyalar temizleniyor...{Colors.ENDC}")
            for segment_path in audio_segments:
                if os.path.exists(segment_path):
                    os.remove(segment_path)
                transcript_path = f"{Path(segment_path).stem}_transkript.txt"
                if os.path.exists(transcript_path):
                    os.remove(transcript_path)

            if os.path.exists(audio_path) and audio_path != file_path:
                os.remove(audio_path)

            print(f"{Colors.OKGREEN}Ge√ßici dosyalar temizlendi{Colors.ENDC}")

        total_elapsed_time = time.time() - total_start_time
        print(f"\n{Colors.BOLD}Toplam i≈ülem s√ºresi: {total_elapsed_time:.2f} saniye ({format_time_duration(total_elapsed_time)}){Colors.ENDC}")

        print(f"\n{Colors.HEADER}TRANSKRƒ∞PT √ñN ƒ∞ZLEME (ilk 500 karakter):{Colors.ENDC}")
        print("=" * 80)
        with open(full_transcript_path, 'r', encoding='utf-8') as f:
            preview = f.read(500) + "..."
            print(preview)
        print("=" * 80)

        return full_transcript_path

    except Exception as e:
        print(f"\n{Colors.FAIL}‚ùå Hata olu≈ütu: {str(e)}{Colors.ENDC}")
        import traceback
        traceback.print_exc()
        return None


def process_youtube_content(youtube_url: str, language: str = "tr", model_size: str = "medium", 
                           high_quality: bool = True, timestamp_output: bool = True, 
                           segment_length_minutes: int = 20, delete_segments_after: bool = True,
                           is_playlist_item: bool = False, playlist_index: Optional[int] = None,
                           enable_speaker_diarization: bool = False,
                           min_speakers: int = 2, max_speakers: int = 10,
                           output_dir: Optional[str] = None,
                           preferred_engine: str = None,
                           engine_order: List[str] = None) -> Optional[str]:
    """YouTube i√ßeriƒüini i≈üler"""
    try:
        clean_title, video_id = get_video_title_and_id(youtube_url)

        if is_playlist_item and playlist_index is not None:
            custom_filename = f"[{playlist_index:02d}]-{clean_title}-{video_id}.txt"
        else:
            custom_filename = f"{clean_title}-{video_id}.txt"

        print(f"\n{Colors.OKBLUE}üìù Transkript dosya adƒ±: {custom_filename}{Colors.ENDC}")

        print(f"\n{Colors.HEADER}--- YOUTUBE SES ƒ∞NDƒ∞RME ---{Colors.ENDC}")
        audio_file_path = download_youtube_audio_direct(youtube_url)

        result = process_file(
            audio_file_path,
            language=language,
            model_size=model_size,
            high_quality=high_quality,
            timestamp_output=timestamp_output,
            segment_length_minutes=segment_length_minutes,
            delete_segments_after=delete_segments_after,
            custom_filename=custom_filename,
            enable_speaker_diarization=enable_speaker_diarization,
            min_speakers=min_speakers,
            max_speakers=max_speakers,
            output_dir=output_dir,
            preferred_engine=preferred_engine,
            engine_order=engine_order
        )

        if delete_segments_after and os.path.exists(audio_file_path):
            print("Orijinal ses dosyasƒ± temizleniyor...")
            os.remove(audio_file_path)
            print("Orijinal ses dosyasƒ± temizlendi")

        return result

    except Exception as e:
        print(f"{Colors.FAIL}‚ùå YouTube i≈üleme hatasƒ±: {str(e)}{Colors.ENDC}")
        import traceback
        traceback.print_exc()
        return None


def process_playlist(playlist_url: str, max_videos: int = 50, continue_on_error: bool = True, 
                    output_dir: Optional[str] = None, **kwargs) -> List[Dict]:
    """YouTube playlist'ini i≈üler"""
    global all_transcript_files

    try:
        print(f"\n{Colors.HEADER}{'='*80}")
        print(f"üé¨ YOUTUBE PLAYLIST ƒ∞≈ûLEME BA≈ûLADI")
        print(f"{'='*80}{Colors.ENDC}")

        videos = get_playlist_videos(playlist_url, max_videos)

        if not videos:
            print(f"{Colors.FAIL}‚ùå Playlist'ten video bilgileri alƒ±namadƒ±!{Colors.ENDC}")
            return []

        print(f"\n{Colors.OKBLUE}üìã Playlist Bilgileri:")
        print(f"   ‚Ä¢ Bulunan video sayƒ±sƒ±: {len(videos)}")
        print(f"   ‚Ä¢ ƒ∞≈ülenecek maksimum video: {max_videos}")
        print(f"   ‚Ä¢ Hatada devam et: {'Evet' if continue_on_error else 'Hayƒ±r'}{Colors.ENDC}")

        all_results = []
        successful_count = 0
        failed_count = 0

        print(f"\n{Colors.HEADER}{'='*80}")
        print(f"üöÄ Vƒ∞DEO ƒ∞≈ûLEME BA≈ûLIYOR")
        print(f"{'='*80}{Colors.ENDC}")

        for i, video in enumerate(videos, 1):
            video_start_time = time.time()

            print(f"\n{Colors.OKCYAN}{'-'*60}")
            print(f"üìπ Video {i}/{len(videos)}")
            print(f"üìå ID: {video['id']}")
            print(f"üìù Ba≈ülƒ±k: {video['title']}")
            print(f"‚è±Ô∏è S√ºre: {video['duration']}")
            print(f"üîó URL: {video['url']}")
            print(f"{'-'*60}{Colors.ENDC}")

            try:
                result_path = process_youtube_content(
                    video['url'],
                    is_playlist_item=True,
                    playlist_index=i,
                    output_dir=output_dir,
                    **kwargs
                )

                if result_path:
                    video_elapsed_time = time.time() - video_start_time

                    all_results.append({
                        'video_info': video,
                        'transcript_path': result_path,
                        'status': 'success',
                        'processing_time': video_elapsed_time
                    })

                    successful_count += 1

                    print(f"\n{Colors.OKGREEN}‚úÖ Video {i} ba≈üarƒ±yla i≈ülendi!")
                    print(f"‚è±Ô∏è ƒ∞≈ülem s√ºresi: {format_time_duration(video_elapsed_time)}")
                    print(f"üìÅ Transkript dosyasƒ±: {result_path}{Colors.ENDC}")

                else:
                    failed_count += 1
                    all_results.append({
                        'video_info': video,
                        'transcript_path': None,
                        'status': 'failed',
                        'error': 'Transkript olu≈üturulamadƒ±'
                    })
                    print(f"\n{Colors.FAIL}‚ùå Video {i} i≈ülenemedi!{Colors.ENDC}")

                    if not continue_on_error:
                        print(f"{Colors.FAIL}‚ùå Hatada durma aktif - i≈ülem durduruldu!{Colors.ENDC}")
                        break

            except Exception as e:
                failed_count += 1
                error_msg = str(e)

                all_results.append({
                    'video_info': video,
                    'transcript_path': None,
                    'status': 'failed',
                    'error': error_msg
                })

                print(f"\n{Colors.FAIL}‚ùå Video {i} i≈üleme hatasƒ±: {error_msg}{Colors.ENDC}")

                if not continue_on_error:
                    print(f"{Colors.FAIL}‚ùå Hatada durma aktif - i≈ülem durduruldu!{Colors.ENDC}")
                    break
                else:
                    print(f"{Colors.WARNING}‚ö†Ô∏è Hatada devam et aktif - bir sonraki videoya ge√ßiliyor...{Colors.ENDC}")

            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

        create_playlist_summary(all_results, playlist_url, output_dir)

        return all_results

    except Exception as e:
        print(f"\n{Colors.FAIL}‚ùå Playlist i≈üleme genel hatasƒ±: {str(e)}{Colors.ENDC}")
        import traceback
        traceback.print_exc()
        return []


def create_playlist_summary(results: List[Dict], playlist_url: str, output_dir: Optional[str] = None) -> None:
    """Playlist i≈üleme √∂zeti olu≈üturur"""
    global all_transcript_files

    print(f"\n{Colors.HEADER}{'='*80}")
    print(f"üìä PLAYLIST ƒ∞≈ûLEME √ñZETƒ∞")
    print(f"{'='*80}{Colors.ENDC}")

    successful_results = [r for r in results if r['status'] == 'success']
    failed_results = [r for r in results if r['status'] == 'failed']

    print(f"{Colors.OKBLUE}üìã Playlist URL: {playlist_url}")
    print(f"üìä Toplam video: {len(results)}")
    print(f"‚úÖ Ba≈üarƒ±lƒ±: {len(successful_results)}")
    print(f"‚ùå Ba≈üarƒ±sƒ±z: {len(failed_results)}{Colors.ENDC}")

    if successful_results:
        total_processing_time = sum(r.get('processing_time', 0) for r in successful_results)
        average_time = total_processing_time / len(successful_results)

        print(f"{Colors.OKGREEN}‚è±Ô∏è Toplam i≈ülem s√ºresi: {format_time_duration(total_processing_time)}")
        print(f"‚è±Ô∏è Ortalama video i≈ülem s√ºresi: {format_time_duration(average_time)}{Colors.ENDC}")

    summary_filename = f"playlist_ozet_{int(time.time())}.txt"
    if output_dir:
        summary_filename = os.path.join(output_dir, summary_filename)

    with open(summary_filename, 'w', encoding='utf-8') as f:
        f.write(f"YouTube Playlist Transkript √ñzeti\n")
        f.write(f"{'='*50}\n\n")
        f.write(f"Playlist URL: {playlist_url}\n")
        f.write(f"ƒ∞≈ülem Tarihi: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write(f"üìä ƒ∞statistikler:\n")
        f.write(f"   ‚Ä¢ Toplam video: {len(results)}\n")
        f.write(f"   ‚Ä¢ Ba≈üarƒ±lƒ±: {len(successful_results)}\n")
        f.write(f"   ‚Ä¢ Ba≈üarƒ±sƒ±z: {len(failed_results)}\n\n")

        if successful_results:
            f.write(f"‚úÖ Ba≈üarƒ±yla ƒ∞≈ülenen Videolar:\n")
            f.write(f"{'-'*40}\n")
            for i, result in enumerate(successful_results, 1):
                video = result['video_info']
                f.write(f"{i}. {video['title']}\n")
                f.write(f"   ‚Ä¢ Video ID: {video['id']}\n")
                f.write(f"   ‚Ä¢ S√ºre: {video['duration']}\n")
                f.write(f"   ‚Ä¢ Transkript: {result['transcript_path']}\n")
                f.write(f"   ‚Ä¢ ƒ∞≈ülem s√ºresi: {format_time_duration(result.get('processing_time', 0))}\n\n")

        if failed_results:
            f.write(f"‚ùå ƒ∞≈ülenemeden Videolar:\n")
            f.write(f"{'-'*40}\n")
            for i, result in enumerate(failed_results, 1):
                video = result['video_info']
                f.write(f"{i}. {video['title']}\n")
                f.write(f"   ‚Ä¢ Video ID: {video['id']}\n")
                f.write(f"   ‚Ä¢ URL: {video['url']}\n")
                f.write(f"   ‚Ä¢ Hata: {result.get('error', 'Bilinmeyen hata')}\n\n")

    print(f"\n{Colors.OKGREEN}üìÅ √ñzet dosyasƒ± olu≈üturuldu: {summary_filename}{Colors.ENDC}")
    all_transcript_files.append(summary_filename)


def get_transcript_settings():
    """Transkript ayarlarƒ±nƒ± kullanƒ±cƒ±dan alƒ±r"""
    settings = {}
    
    # Transkript motoru se√ßimi
    available_engines = TranscriptEngine.get_available_engines()
    if not available_engines:
        print(f"{Colors.FAIL}Hi√ßbir transkript motoru bulunamadƒ±!{Colors.ENDC}")
        return None
    
    print(f"\n{Colors.OKGREEN}Kullanƒ±labilir transkript motorlarƒ±:{Colors.ENDC}")
    engine_options = []
    if TranscriptEngine.WHISPER in available_engines:
        engine_options.append("Whisper (OpenAI) - En doƒüru, GPU destekli")
    if TranscriptEngine.VOSK in available_engines:
        engine_options.append("Vosk - Hƒ±zlƒ±, √ßevrimdƒ±≈üƒ±")
    if TranscriptEngine.GOOGLE in available_engines:
        engine_options.append("Google Speech API - √úcretsiz, internet gerekli")
    engine_options.append("Otomatik (ba≈üarƒ±sƒ±zlƒ±kta diƒüerlerini dene)")
    
    engine_choice = get_user_choice("Transkript motoru se√ßin:", engine_options)
    
    if "Whisper" in engine_choice:
        settings['preferred_engine'] = TranscriptEngine.WHISPER
    elif "Vosk" in engine_choice:
        settings['preferred_engine'] = TranscriptEngine.VOSK
    elif "Google" in engine_choice:
        settings['preferred_engine'] = TranscriptEngine.GOOGLE
    else:
        settings['preferred_engine'] = None  # Otomatik
    
    # Motor sƒ±ralamasƒ±
    if settings['preferred_engine'] is None:
        print(f"\n{Colors.OKBLUE}Otomatik mod se√ßildi. Motor √∂ncelik sƒ±rasƒ±:{Colors.ENDC}")
        print("1. Whisper (en doƒüru)")
        print("2. Vosk (√ßevrimdƒ±≈üƒ±)")
        print("3. Google Speech (internet gerekli)")
        settings['engine_order'] = None  # Varsayƒ±lan sƒ±ra kullanƒ±lacak
    
    # Dil se√ßimi
    languages = {
        'T√ºrk√ße': 'tr',
        'ƒ∞ngilizce': 'en',
        'Almanca': 'de',
        'Fransƒ±zca': 'fr',
        'ƒ∞spanyolca': 'es',
        'ƒ∞talyanca': 'it',
        'Rus√ßa': 'ru',
        'Arap√ßa': 'ar',
        '√áince': 'zh',
        'Japonca': 'ja',
        'Korece': 'ko',
        'Portekizce': 'pt'
    }
    
    lang_choice = get_user_choice("Transkript dili se√ßin:", list(languages.keys()))
    settings['language'] = languages[lang_choice]
    
    # Model boyutu (sadece Whisper i√ßin)
    if settings.get('preferred_engine') == TranscriptEngine.WHISPER or settings.get('preferred_engine') is None:
        if gpu_baglanti_kontrol():
            models = ['tiny', 'base', 'small', 'medium', 'large']
            default_model = 'medium'
        else:
            models = ['tiny', 'base', 'small', 'medium']
            default_model = 'small'
            print(f"{Colors.WARNING}Not: GPU olmadƒ±ƒüƒ± i√ßin 'large' model √∂nerilmez{Colors.ENDC}")
        
        model_choice = get_user_choice(f"Whisper model boyutu se√ßin (√∂nerilen: {default_model}):", models)
        settings['model_size'] = model_choice
    else:
        settings['model_size'] = 'medium'  # Varsayƒ±lan
    
    # Kalite ayarƒ±
    settings['high_quality'] = get_yes_no("Y√ºksek kalite modu kullanƒ±lsƒ±n mƒ±? (daha yava≈ü ama daha doƒüru)")
    
    # Zaman damgasƒ±
    settings['timestamp_output'] = get_yes_no("Zaman damgalarƒ± eklensin mi?")
    
    # Segment uzunluƒüu
    segment_options = ['5', '10', '15', '20', '30', '60']
    segment_choice = get_user_choice("Segment uzunluƒüu (dakika):", segment_options, allow_custom=True)
    settings['segment_length_minutes'] = int(segment_choice)
    
    # Ge√ßici dosyalar
    settings['delete_segments_after'] = get_yes_no("ƒ∞≈ülem sonrasƒ± ge√ßici dosyalar silinsin mi?")
    
    # Konu≈ümacƒ± ayrƒ±mƒ±
    settings['enable_speaker_diarization'] = get_yes_no("Konu≈ümacƒ± ayrƒ±mƒ± yapƒ±lsƒ±n mƒ±?")
    
    if settings['enable_speaker_diarization']:
        settings['huggingface_token'] = input(f"{Colors.WARNING}HuggingFace token: {Colors.ENDC}")
        
        min_speakers = input(f"{Colors.WARNING}Minimum konu≈ümacƒ± sayƒ±sƒ± (varsayƒ±lan 2): {Colors.ENDC}")
        settings['min_speakers'] = int(min_speakers) if min_speakers else 2
        
        max_speakers = input(f"{Colors.WARNING}Maksimum konu≈ümacƒ± sayƒ±sƒ± (varsayƒ±lan 10): {Colors.ENDC}")
        settings['max_speakers'] = int(max_speakers) if max_speakers else 10
    
    return settings


def process_local_files():
    """Yerel dosyalarƒ± i≈üle"""
    print(f"\n{Colors.BOLD}Yerel Dosya/Klas√∂r ƒ∞≈üleme{Colors.ENDC}")
    
    files, output_dir = select_files_or_folder_gui()
    
    if not files:
        print(f"{Colors.FAIL}Dosya se√ßimi iptal edildi veya dosya bulunamadƒ±!{Colors.ENDC}")
        return
    
    print(f"\n{Colors.OKGREEN}Se√ßilen dosya sayƒ±sƒ±: {len(files)}{Colors.ENDC}")
    for i, file in enumerate(files, 1):
        print(f"{Colors.OKBLUE}{i}. {os.path.basename(file)}{Colors.ENDC}")
    
    # Ayarlarƒ± al
    settings = get_transcript_settings()
    if settings is None:
        return
    
    # Konu≈ümacƒ± ayrƒ±mƒ± ba≈ülat
    if settings.get('enable_speaker_diarization') and settings.get('huggingface_token'):
        initialize_diarization_pipeline(
            settings['huggingface_token'],
            settings.get('min_speakers', 2),
            settings.get('max_speakers', 10)
        )
    
    # Her dosyayƒ± i≈üle
    all_results = []
    for i, file_path in enumerate(files, 1):
        print(f"\n{Colors.HEADER}{'='*60}")
        print(f"Dosya {i}/{len(files)}: {os.path.basename(file_path)}")
        print(f"{'='*60}{Colors.ENDC}")
        
        # Dosya adƒ±na g√∂re transkript adƒ±
        base_name = os.path.splitext(os.path.basename(file_path))[0]
        custom_filename = f"{base_name}_transkript.txt"
        
        result = process_file(
            file_path,
            language=settings.get('language', 'tr'),
            model_size=settings.get('model_size', 'medium'),
            high_quality=settings.get('high_quality', True),
            timestamp_output=settings.get('timestamp_output', True),
            segment_length_minutes=settings.get('segment_length_minutes', 20),
            delete_segments_after=settings.get('delete_segments_after', True),
            custom_filename=custom_filename,
            enable_speaker_diarization=settings.get('enable_speaker_diarization', False),
            min_speakers=settings.get('min_speakers', 2),
            max_speakers=settings.get('max_speakers', 10),
            output_dir=output_dir,
            preferred_engine=settings.get('preferred_engine'),
            engine_order=settings.get('engine_order')
        )
        
        if result:
            all_results.append(result)
            print(f"{Colors.OKGREEN}‚úÖ Dosya ba≈üarƒ±yla i≈ülendi!{Colors.ENDC}")
        else:
            print(f"{Colors.FAIL}‚ùå Dosya i≈ülenemedi!{Colors.ENDC}")
    
    # ZIP olu≈ütur
    if len(all_results) > 1 and get_yes_no("T√ºm transkriptleri ZIP dosyasƒ± olarak paketlensin mi?"):
        timestamp = int(time.time())
        zip_filename = f"toplu_transkriptler_{timestamp}.zip"
        if output_dir:
            zip_filename = os.path.join(output_dir, zip_filename)
        
        create_zip_archive(all_results, zip_filename)
        
        if get_yes_no("ZIP olu≈üturuldu. Tekil dosyalar silinsin mi?"):
            for file_path in all_results:
                if os.path.exists(file_path):
                    os.remove(file_path)
            print(f"{Colors.OKGREEN}‚úÖ Tekil dosyalar silindi{Colors.ENDC}")


def process_youtube_videos():
    """YouTube video/playlist i≈üle"""
    print(f"\n{Colors.BOLD}YouTube Video/Playlist ƒ∞≈üleme{Colors.ENDC}")
    
    url = input(f"\n{Colors.WARNING}YouTube URL'si (video veya playlist): {Colors.ENDC}").strip()
    
    if not url:
        print(f"{Colors.FAIL}URL bo≈ü olamaz!{Colors.ENDC}")
        return
    
    # Playlist kontrol√º
    if is_playlist_url(url):
        print(f"\n{Colors.OKGREEN}‚úÖ Playlist URL'si tespit edildi!{Colors.ENDC}")
        
        max_videos = input(f"{Colors.WARNING}Maksimum video sayƒ±sƒ± (varsayƒ±lan 50): {Colors.ENDC}")
        max_videos = int(max_videos) if max_videos else 50
        
        continue_on_error = get_yes_no("Hata durumunda devam edilsin mi?")
        
        # √áƒ±ktƒ± dizini
        output_dir = None
        if get_yes_no("Transkriptler i√ßin √∂zel bir klas√∂r se√ßmek ister misiniz?"):
            root = tk.Tk()
            root.withdraw()
            output_dir = filedialog.askdirectory(title="Transkriptler i√ßin klas√∂r se√ßin")
            root.destroy()
        
        # Ayarlarƒ± al
        settings = get_transcript_settings()
        if settings is None:
            return
        
        # Konu≈ümacƒ± ayrƒ±mƒ± ba≈ülat
        if settings.get('enable_speaker_diarization') and settings.get('huggingface_token'):
            initialize_diarization_pipeline(
                settings['huggingface_token'],
                settings.get('min_speakers', 2),
                settings.get('max_speakers', 10)
            )
        
        # Playlist'i i≈üle
        process_playlist(
            url,
            max_videos=max_videos,
            continue_on_error=continue_on_error,
            output_dir=output_dir,
            **settings
        )
        
    else:
        print(f"\n{Colors.OKGREEN}‚úÖ Tekil video URL'si tespit edildi!{Colors.ENDC}")
        
        # √áƒ±ktƒ± dizini
        output_dir = None
        if get_yes_no("Transkript i√ßin √∂zel bir klas√∂r se√ßmek ister misiniz?"):
            root = tk.Tk()
            root.withdraw()
            output_dir = filedialog.askdirectory(title="Transkript i√ßin klas√∂r se√ßin")
            root.destroy()
        
        # Ayarlarƒ± al
        settings = get_transcript_settings()
        if settings is None:
            return
        
        # Konu≈ümacƒ± ayrƒ±mƒ± ba≈ülat
        if settings.get('enable_speaker_diarization') and settings.get('huggingface_token'):
            initialize_diarization_pipeline(
                settings['huggingface_token'],
                settings.get('min_speakers', 2),
                settings.get('max_speakers', 10)
            )
        
        # Video'yu i≈üle
        process_youtube_content(
            url,
            is_playlist_item=False,
            output_dir=output_dir,
            **settings
        )


def show_main_menu():
    """Ana men√ºy√º g√∂ster"""
    while True:
        print_header()
        
        print(f"{Colors.BOLD}Ana Men√º:{Colors.ENDC}")
        print(f"{Colors.OKBLUE}1.{Colors.ENDC} YouTube Video/Playlist ƒ∞≈üle")
        print(f"{Colors.OKBLUE}2.{Colors.ENDC} Yerel Dosya/Klas√∂r ƒ∞≈üle")
        print(f"{Colors.OKBLUE}3.{Colors.ENDC} Hakkƒ±nda")
        print(f"{Colors.OKBLUE}4.{Colors.ENDC} √áƒ±kƒ±≈ü")
        
        choice = input(f"\n{Colors.WARNING}Se√ßiminiz (1-4): {Colors.ENDC}")
        
        if choice == '1':
            process_youtube_videos()
            input(f"\n{Colors.WARNING}Devam etmek i√ßin Enter'a basƒ±n...{Colors.ENDC}")
            
        elif choice == '2':
            process_local_files()
            input(f"\n{Colors.WARNING}Devam etmek i√ßin Enter'a basƒ±n...{Colors.ENDC}")
            
        elif choice == '3':
            show_about()
            input(f"\n{Colors.WARNING}Devam etmek i√ßin Enter'a basƒ±n...{Colors.ENDC}")
            
        elif choice == '4':
            print(f"\n{Colors.OKGREEN}Program kapatƒ±lƒ±yor...{Colors.ENDC}")
            break
            
        else:
            print(f"{Colors.FAIL}Ge√ßersiz se√ßim! L√ºtfen 1-4 arasƒ± bir sayƒ± girin.{Colors.ENDC}")
            time.sleep(1)


def show_about():
    """Hakkƒ±nda b√∂l√ºm√º"""
    clear_screen()
    print(f"{Colors.HEADER}{'='*80}{Colors.ENDC}")
    print(f"{Colors.BOLD}{Colors.OKCYAN}YouTube Video/Playlist Transkript Olu≈üturucu - √áoklu Motor{Colors.ENDC}")
    print(f"{Colors.HEADER}{'='*80}{Colors.ENDC}")
    
    print(f"\n{Colors.OKGREEN}üìù √ñzellikler:{Colors.ENDC}")
    print("  ‚Ä¢ YouTube video ve playlist desteƒüi")
    print("  ‚Ä¢ Yerel video/ses dosyalarƒ± desteƒüi")
    print("  ‚Ä¢ Toplu dosya i≈üleme")
    print("  ‚Ä¢ GPU hƒ±zlandƒ±rma")
    print("  ‚Ä¢ Konu≈ümacƒ± ayrƒ±mƒ±")
    print("  ‚Ä¢ √áoklu dil desteƒüi")
    print("  ‚Ä¢ Zaman damgalƒ± transkript")
    print("  ‚Ä¢ ZIP ar≈üivleme")
    print("  ‚Ä¢ √áoklu transkript motoru desteƒüi")
    print("  ‚Ä¢ Otomatik yedek motor ge√ßi≈üi")
    
    print(f"\n{Colors.OKBLUE}üõ†Ô∏è Transkript Motorlarƒ±:{Colors.ENDC}")
    available_engines = TranscriptEngine.get_available_engines()
    print(f"  ‚Ä¢ Whisper (OpenAI): {'‚úÖ Y√ºkl√º' if TranscriptEngine.WHISPER in available_engines else '‚ùå Y√ºkl√º deƒüil'}")
    print(f"  ‚Ä¢ Vosk: {'‚úÖ Y√ºkl√º' if TranscriptEngine.VOSK in available_engines else '‚ùå Y√ºkl√º deƒüil'}")
    print(f"  ‚Ä¢ Google Speech API: {'‚úÖ Y√ºkl√º' if TranscriptEngine.GOOGLE in available_engines else '‚ùå Y√ºkl√º deƒüil'}")
    
    print(f"\n{Colors.WARNING}‚öôÔ∏è Sistem Gereksinimleri:{Colors.ENDC}")
    print("  ‚Ä¢ Python 3.8+")
    print("  ‚Ä¢ FFmpeg")
    print("  ‚Ä¢ 8GB+ RAM (√∂nerilen)")
    print("  ‚Ä¢ NVIDIA GPU (opsiyonel, √∂nerilen)")
    
    print(f"\n{Colors.OKCYAN}üë®‚Äçüíª Geli≈ütirici: AI Assistant{Colors.ENDC}")
    print(f"{Colors.OKCYAN}üìÖ Versiyon: 3.0 (√áoklu Motor Destekli){Colors.ENDC}")


def main():
    """Ana program fonksiyonu"""
    try:
        # Ba≈ülangƒ±√ß kontrollarƒ±
        print_header()
        
        print(f"{Colors.OKBLUE}Sistem kontrolleri yapƒ±lƒ±yor...{Colors.ENDC}")
        
        # Baƒüƒ±mlƒ±lƒ±k kontrol√º
        if not check_dependencies():
            print(f"\n{Colors.FAIL}Gerekli baƒüƒ±mlƒ±lƒ±klar eksik! L√ºtfen yukarƒ±daki hatalarƒ± d√ºzeltin.{Colors.ENDC}")
            input(f"\n{Colors.WARNING}√áƒ±kmak i√ßin Enter'a basƒ±n...{Colors.ENDC}")
            sys.exit(1)
        
        # GPU kontrol√º
        gpu_baglanti_kontrol()
        
        print(f"\n{Colors.OKGREEN}‚úÖ T√ºm kontroller ba≈üarƒ±lƒ±!{Colors.ENDC}")
        time.sleep(1)
        
        # Ana men√ºy√º g√∂ster
        show_main_menu()
        
    except KeyboardInterrupt:
        print(f"\n\n{Colors.WARNING}‚ö†Ô∏è ƒ∞≈ülem kullanƒ±cƒ± tarafƒ±ndan iptal edildi{Colors.ENDC}")
        sys.exit(130)
    except Exception as e:
        print(f"\n{Colors.FAIL}‚ùå Beklenmeyen hata: {str(e)}{Colors.ENDC}")
        import traceback
        traceback.print_exc()
        input(f"\n{Colors.WARNING}√áƒ±kmak i√ßin Enter'a basƒ±n...{Colors.ENDC}")
        sys.exit(1)


if __name__ == "__main__":
    main()